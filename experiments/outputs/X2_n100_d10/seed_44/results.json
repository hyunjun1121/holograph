{
  "_metadata": {
    "experiment_id": "X2_n100_d10",
    "description": "Sheaf Axiom: Transitivity (rho_ZU = rho_ZV o rho_VU) (n=100, depth=10)",
    "hypothesis": "Transitivity error < epsilon for all context triples",
    "claims_supported": [
      "T2"
    ],
    "config": {
      "experiment_id": "X2_n100_d10",
      "description": "Sheaf Axiom: Transitivity (rho_ZU = rho_ZV o rho_VU) (n=100, depth=10)",
      "hypothesis": "Transitivity error < epsilon for all context triples",
      "claims_supported": [
        "T2"
      ],
      "method": "holograph",
      "n_vars": 100,
      "learning_rate": 0.01,
      "lambda_descent": 1.0,
      "lambda_spec": 0.1,
      "lambda_reg": 0.0001,
      "max_steps": 500,
      "use_natural_gradient": true,
      "dataset": "sf",
      "dataset_kwargs": {
        "avg_degree": 2.0
      },
      "seed": 44,
      "llm_provider": "sglang",
      "llm_model_role": "primary",
      "llm_api_key": null,
      "use_llm": true,
      "embedding_model": "Alibaba-NLP/gte-Qwen2-7B-instruct",
      "embedding_api_key": null,
      "use_embeddings": false,
      "use_active_queries": true,
      "max_queries_per_step": 3,
      "query_interval": 25,
      "max_total_queries": 100,
      "max_total_tokens": 500000,
      "output_dir": "experiments/outputs",
      "save_checkpoints": true,
      "checkpoint_interval": 100
    },
    "git_commit": "unknown",
    "slurm_job_id": "2765672",
    "seed": 44,
    "timestamp": "2025-12-30T19:47:56.550962",
    "wall_time_seconds": 31.627262353897095,
    "dataset": "SF_n100_d2.0"
  },
  "results": {
    "identity_max": 0.0,
    "identity_mean": 0.0,
    "transitivity_max": 2.9813034885251e-06,
    "transitivity_mean": 1.725012730368507e-06,
    "locality_max": 3.463379144668579,
    "locality_mean": 0.7656768807010051,
    "gluing_max": 0.0,
    "gluing_mean": 0.0,
    "passes_identity_passes": true,
    "passes_transitivity_passes": true,
    "passes_locality_passes": false,
    "passes_gluing_passes": true,
    "wall_time_seconds": 31.583060026168823,
    "num_queries": 36,
    "training_steps": 300,
    "final_loss": {
      "total": 0.5740157961845398,
      "spectral_radius": 0.3504091501235962,
      "acyclicity": 0.0037689208984375
    },
    "llm_usage": {
      "total_input_tokens": 0,
      "total_output_tokens": 0,
      "total_queries": 0,
      "model": "deepseek-ai/DeepSeek-V3.2-Exp-thinking-on",
      "model_role": "primary"
    }
  },
  "artifacts": {
    "learned_graph": "experiments/outputs/X2_n100_d10/seed_44/graph.npz",
    "training_log": "experiments/outputs/X2_n100_d10/seed_44/training.csv",
    "checkpoint": "experiments/outputs/X2_n100_d10/seed_44/checkpoint.pt"
  }
}