{
  "_metadata": {
    "experiment_id": "A5_sachs",
    "description": "Ablation: Fast model (thinking-off) vs Primary (thinking-on) on sachs",
    "hypothesis": "Extended thinking improves complex causal reasoning",
    "claims_supported": [
      "C1"
    ],
    "config": {
      "experiment_id": "A5_sachs",
      "description": "Ablation: Fast model (thinking-off) vs Primary (thinking-on) on sachs",
      "hypothesis": "Extended thinking improves complex causal reasoning",
      "claims_supported": [
        "C1"
      ],
      "method": "holograph",
      "n_vars": 11,
      "learning_rate": 0.01,
      "lambda_descent": 1.0,
      "lambda_spec": 0.1,
      "lambda_reg": 0.0001,
      "max_steps": 1000,
      "use_natural_gradient": true,
      "dataset": "sachs",
      "dataset_kwargs": {},
      "seed": 46,
      "llm_provider": "sglang",
      "llm_model_role": "fast",
      "llm_api_key": null,
      "use_llm": true,
      "embedding_model": "Alibaba-NLP/gte-Qwen2-7B-instruct",
      "embedding_api_key": null,
      "use_embeddings": false,
      "use_active_queries": true,
      "max_queries_per_step": 3,
      "query_interval": 50,
      "max_total_queries": 100,
      "max_total_tokens": 500000,
      "output_dir": "experiments/outputs",
      "save_checkpoints": true,
      "checkpoint_interval": 100
    },
    "git_commit": "unknown",
    "slurm_job_id": "2764869",
    "seed": 46,
    "timestamp": "2025-12-30T19:42:43.237409",
    "wall_time_seconds": 0.4978816509246826,
    "dataset": "SACHS"
  },
  "results": {
    "shd": 19,
    "shd_undirected": 15,
    "sid": 25.0,
    "precision": 0.45454545454545453,
    "recall": 0.29411764705882354,
    "f1": 0.35714285714285715,
    "tp": 5,
    "fp": 6,
    "fn": 12,
    "final_loss_total": 0.051083892583847046,
    "final_spectral_radius": 0.4675673246383667,
    "final_acyclicity": 0.022523880004882812,
    "wall_time_seconds": 0.46469545364379883,
    "num_queries": 60,
    "training_steps": 1001,
    "final_loss": {
      "total": 0.051083892583847046,
      "spectral_radius": 0.4675673246383667,
      "acyclicity": 0.022523880004882812
    },
    "llm_usage": {
      "total_input_tokens": 0,
      "total_output_tokens": 0,
      "total_queries": 0,
      "model": "togetherai/deepseek-ai/DeepSeek-V3-0324",
      "model_role": "fast"
    }
  },
  "artifacts": {
    "learned_graph": "experiments/outputs/A5_sachs/seed_46/graph.npz",
    "training_log": "experiments/outputs/A5_sachs/seed_46/training.csv",
    "checkpoint": "experiments/outputs/A5_sachs/seed_46/checkpoint.pt"
  }
}